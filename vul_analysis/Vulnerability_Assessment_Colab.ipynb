{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6f2b52",
   "metadata": {},
   "source": [
    "# Vulnerability Assessment (DSPy + Gemini) - Google Colab\n",
    "\n",
    "This notebook clones the LLM-Assisted-Container-Security-Analysis repository from GitHub, installs dependencies, and runs a DSPy/Gemini-based vulnerability assessment on combined scanner reports (Trivy + Grype).\n",
    "\n",
    "## Before Running\n",
    "1. You'll need a **GEMINI_API_KEY** (Google AI Studio API key)\n",
    "2. Run all cells in order from top to bottom\n",
    "3. When prompted, enter your API key in the secure input field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2cfc6",
   "metadata": {},
   "source": [
    "## Step 1: Clone the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone the repository if not already present\n",
    "if not os.path.exists('/content/LLM-Assisted-Container-Security-Analysis'):\n",
    "    !git clone https://github.com/satyam-thakur/LLM-Assisted-Container-Security-Analysis.git\n",
    "    print('✓ Repository cloned successfully')\n",
    "else:\n",
    "    print('✓ Repository already exists')\n",
    "\n",
    "# Change to the repository directory\n",
    "os.chdir('/content/LLM-Assisted-Container-Security-Analysis')\n",
    "print(f'Current directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861cbff",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages from vul_analysis requirements\n",
    "!pip install -q -r vul_analysis/requirements.txt\n",
    "print('✓ Dependencies installed successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f25b4b6",
   "metadata": {},
   "source": [
    "## Step 3: Configure API Key\n",
    "\n",
    "Enter your Google Gemini API key. You can get one from [Google AI Studio](https://makersuite.google.com/app/apikey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b586bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Prompt for API key securely\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    api_key = getpass('Enter your GEMINI_API_KEY: ')\n",
    "    os.environ['GEMINI_API_KEY'] = api_key\n",
    "    print('✓ API key configured')\n",
    "else:\n",
    "    print('✓ API key already configured')\n",
    "\n",
    "# Set default model if not specified\n",
    "if 'GEMINI_MODEL' not in os.environ:\n",
    "    os.environ['GEMINI_MODEL'] = 'gemini-1.5-flash'\n",
    "\n",
    "# Optional: Set temperature\n",
    "if 'LM_TEMPERATURE' not in os.environ:\n",
    "    os.environ['LM_TEMPERATURE'] = '0.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333d0e4",
   "metadata": {},
   "source": [
    "## Step 4: Verify Files and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024535ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the repository root to Python path\n",
    "repo_root = '/content/LLM-Assisted-Container-Security-Analysis'\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "# Verify key files exist\n",
    "scanner_file = os.path.join(repo_root, 'Scanner/combined_results/hyperledger_fabric-peer_1.1.0_combined.json')\n",
    "vul_analysis_dir = os.path.join(repo_root, 'vul_analysis')\n",
    "\n",
    "print('Checking files:')\n",
    "print(f'  Scanner file exists: {os.path.exists(scanner_file)}')\n",
    "print(f'  vul_analysis directory exists: {os.path.exists(vul_analysis_dir)}')\n",
    "print(f'  Scanner file path: {scanner_file}')\n",
    "\n",
    "# Create outputs directory if it doesn't exist\n",
    "outputs_dir = os.path.join(vul_analysis_dir, 'outputs')\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "print(f'  Outputs directory: {outputs_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a57718",
   "metadata": {},
   "source": [
    "## Step 5: Run Vulnerability Assessment\n",
    "\n",
    "This cell loads the scanner results, runs the AI-powered assessment, and displays a summary.\n",
    "\n",
    "**Note:** This may take several minutes depending on the number of vulnerabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ee4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from vul_analysis.run_assessment import assess\n",
    "\n",
    "# Define input file path\n",
    "INPUT_FILE = '/content/LLM-Assisted-Container-Security-Analysis/Scanner/combined_results/hyperledger_fabric-peer_1.1.0_combined.json'\n",
    "\n",
    "print('Starting vulnerability assessment...')\n",
    "print(f'Input file: {INPUT_FILE}')\n",
    "print('This may take several minutes...\\n')\n",
    "\n",
    "# Run the assessment\n",
    "result = assess(INPUT_FILE, output_dir='/content/LLM-Assisted-Container-Security-Analysis/vul_analysis/outputs')\n",
    "\n",
    "print('\\n✓ Assessment complete!')\n",
    "print(f'JSON report: {result[\"json_path\"]}')\n",
    "print(f'Markdown report: {result[\"md_path\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391ddb8",
   "metadata": {},
   "source": [
    "## Step 6: Display Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary DataFrame\n",
    "print('\\n=== Vulnerability Assessment Summary ===')\n",
    "summary_df = result['summary_df']\n",
    "print(f'Total vulnerabilities assessed: {len(summary_df)}')\n",
    "print(f'\\nAffected vulnerabilities: {summary_df[\"affected\"].sum()}')\n",
    "print(f'Not affected: {(~summary_df[\"affected\"]).sum()}')\n",
    "\n",
    "# Show label distribution\n",
    "print('\\n=== Label Distribution ===')\n",
    "print(summary_df['label'].value_counts())\n",
    "\n",
    "# Show risk distribution\n",
    "print('\\n=== Risk Distribution ===')\n",
    "print(summary_df['risk'].value_counts())\n",
    "\n",
    "# Display first few results\n",
    "print('\\n=== First 10 Results ===')\n",
    "display(summary_df[['vuln_id', 'package_name', 'affected', 'label', 'risk']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c9074",
   "metadata": {},
   "source": [
    "## Step 7: View Detailed Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6acfc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full dataframe with reasons and remediation\n",
    "print('=== Detailed Results ===')\n",
    "display(summary_df[['vuln_id', 'package_name', 'affected', 'label', 'risk', 'reason', 'remediation']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb2eab3",
   "metadata": {},
   "source": [
    "## Step 8: View JSON Output (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display JSON output\n",
    "with open(result['json_path'], 'r', encoding='utf-8') as f:\n",
    "    json_output = json.load(f)\n",
    "\n",
    "print('=== JSON Output Structure ===')\n",
    "print(f\"Keys: {list(json_output.keys())}\")\n",
    "print(f\"\\nInput metadata:\")\n",
    "print(f\"  Image: {json_output['input']['image']}\")\n",
    "print(f\"  Scanners: {json_output['input']['scanners_used']}\")\n",
    "print(f\"  Total vulnerabilities: {json_output['input']['total_vulnerabilities']}\")\n",
    "print(f\"\\nAssessed: {len(json_output['output'])} vulnerabilities\")\n",
    "\n",
    "# Show first result as example\n",
    "print('\\n=== Example Result ===')\n",
    "print(json.dumps(json_output['output'][0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e0480",
   "metadata": {},
   "source": [
    "## Step 9: Preview Markdown Report (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386132d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 50 lines of markdown report\n",
    "with open(result['md_path'], 'r', encoding='utf-8') as f:\n",
    "    md_content = f.read()\n",
    "\n",
    "lines = md_content.split('\\n')\n",
    "preview_lines = min(50, len(lines))\n",
    "print(f'=== Markdown Report Preview (first {preview_lines} lines) ===')\n",
    "print('\\n'.join(lines[:preview_lines]))\n",
    "if len(lines) > 50:\n",
    "    print(f'\\n... ({len(lines) - 50} more lines)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a12f5a",
   "metadata": {},
   "source": [
    "## Step 10: Download Results\n",
    "\n",
    "Run this cell to download the JSON and Markdown reports to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download JSON report\n",
    "print('Downloading JSON report...')\n",
    "files.download(result['json_path'])\n",
    "\n",
    "# Download Markdown report\n",
    "print('Downloading Markdown report...')\n",
    "files.download(result['md_path'])\n",
    "\n",
    "print('✓ Downloads initiated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400082e",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **DSPy Integration**: If DSPy cannot be configured with Gemini in the Colab environment, the pipeline automatically falls back to direct Gemini API calls.\n",
    "- **Output Location**: All outputs are saved to `/content/LLM-Assisted-Container-Security-Analysis/vul_analysis/outputs/`\n",
    "- **Performance**: Processing ~650 vulnerabilities may take 10-30 minutes depending on API rate limits and response times.\n",
    "- **Labels Used**: `vulnerable`, `code_not_present`, `code_not_reachable`, `mitigated`, `fixed`, `false_positive`\n",
    "- **Custom Input**: To analyze a different scanner file, modify the `INPUT_FILE` path in Step 5.\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "- **API Key Issues**: Make sure your GEMINI_API_KEY is valid and has sufficient quota.\n",
    "- **Import Errors**: Re-run Step 2 to ensure all dependencies are installed.\n",
    "- **Rate Limits**: If you hit rate limits, the script may fail partway through. Consider adding rate limiting or retry logic.\n",
    "\n",
    "## Repository\n",
    "\n",
    "GitHub: [satyam-thakur/LLM-Assisted-Container-Security-Analysis](https://github.com/satyam-thakur/LLM-Assisted-Container-Security-Analysis)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
