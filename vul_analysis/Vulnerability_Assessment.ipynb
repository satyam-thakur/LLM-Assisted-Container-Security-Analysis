{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3551cc41",
   "metadata": {},
   "source": [
    "# AI-Vulnerability Assessment\n",
    "\n",
    "This notebook performs AI-powered vulnerability assessment on container scanner results (Trivy + Grype)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f635758",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone the repository if not already present\n",
    "if not os.path.exists('/content/LLM-Assisted-Container-Security-Analysis'):\n",
    "    !git clone https://github.com/satyam-thakur/LLM-Assisted-Container-Security-Analysis.git\n",
    "    print('✓ Repository cloned successfully')\n",
    "else:\n",
    "    print('✓ Repository already exists')\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q dspy-ai>=2.6.20 pandas ujson python-dotenv pydantic rich requests google-generativeai\n",
    "print('✓ Dependencies installed')\n",
    "\n",
    "# Set up paths\n",
    "repo_root = '/content/LLM-Assisted-Container-Security-Analysis'\n",
    "os.chdir(repo_root)\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "print(f'✓ Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d8c0b",
   "metadata": {},
   "source": [
    "## Step 2: Configure API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6421b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "# Prompt for API key securely\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    api_key = getpass('Enter your GEMINI_API_KEY: ')\n",
    "    os.environ['GEMINI_API_KEY'] = api_key\n",
    "    print('✓ API key configured')\n",
    "else:\n",
    "    print('✓ API key already set')\n",
    "\n",
    "# Set defaults\n",
    "os.environ.setdefault('GEMINI_MODEL', 'gemini-1.5-flash')\n",
    "os.environ.setdefault('LM_TEMPERATURE', '0.2')\n",
    "print(f'Model: {os.environ[\"GEMINI_MODEL\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f431d617",
   "metadata": {},
   "source": [
    "## Step 3: Configuration Module\n",
    "\n",
    "Handles environment variables and DSPy configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b13fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "def get_env(key: str, default: Optional[str] = None) -> Optional[str]:\n",
    "    return os.environ.get(key, default)\n",
    "\n",
    "def get_gemini_settings() -> Tuple[Optional[str], str]:\n",
    "    api_key = get_env(\"GEMINI_API_KEY\") or get_env(\"GOOGLE_API_KEY\")\n",
    "    model = get_env(\"GEMINI_MODEL\", \"gemini-1.5-flash\")\n",
    "    return api_key, model\n",
    "\n",
    "def configure_dspy() -> str:\n",
    "    \"\"\"\n",
    "    Try to configure DSPy to use Gemini. Returns:\n",
    "    - \"dspy\": DSPy configured successfully\n",
    "    - \"fallback\": Use direct Gemini API\n",
    "    \"\"\"\n",
    "    api_key, model = get_gemini_settings()\n",
    "    try:\n",
    "        import dspy\n",
    "        lm_name_candidates = [f\"google/{model}\", f\"gemini/{model}\", model]\n",
    "        configured = False\n",
    "        last_err = None\n",
    "        for lm_name in lm_name_candidates:\n",
    "            try:\n",
    "                dspy.configure(lm=dspy.LM(model=lm_name, api_key=api_key), \n",
    "                             temperature=float(get_env(\"LM_TEMPERATURE\", \"0.2\")))\n",
    "                configured = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                continue\n",
    "        if not configured:\n",
    "            if os.getenv(\"DEBUG_DSPY_SETUP\") == \"1\":\n",
    "                print(f\"[WARN] DSPy Gemini LM configuration failed: {last_err}\")\n",
    "            return \"fallback\"\n",
    "        return \"dspy\"\n",
    "    except Exception as e:\n",
    "        if os.getenv(\"DEBUG_DSPY_SETUP\") == \"1\":\n",
    "            print(f\"[WARN] DSPy not available or config failed: {e}\")\n",
    "        return \"fallback\"\n",
    "\n",
    "print('✓ Configuration module loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd8b7ef",
   "metadata": {},
   "source": [
    "## Step 4: Prompts & Labels Module\n",
    "\n",
    "Defines VEX labels and LLM instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "LABEL_CHOICES: List[str] = [\n",
    "    \"vulnerable\",         # exploitable as-deployed\n",
    "    \"code_not_present\",   # package/code not present in image\n",
    "    \"code_not_reachable\", # present but not reachable/exposed\n",
    "    \"mitigated\",          # present, but mitigations block exploit\n",
    "    \"fixed\",              # fixed version present\n",
    "    \"false_positive\",     # scanner likely wrong\n",
    "]\n",
    "\n",
    "SYSTEM_INSTRUCTIONS = f\"\"\"\n",
    "You are a security expert performing container vulnerability validation.\n",
    "Given a vulnerability record from scanners (e.g., Trivy/Grype) for a specific container image, decide if the vulnerability is exploitable in the current context.\n",
    "Return ONLY a strict JSON object with the following keys: affected (boolean), label (one of {LABEL_CHOICES}), reason (<=120 words), risk (low|medium|high), remediation (<=120 words).\n",
    "Be precise, reduce speculation, and ground your decision in the provided details.\n",
    "\"\"\"\n",
    "\n",
    "# DSPy Signature definition (optional)\n",
    "VEXSignature = None\n",
    "try:\n",
    "    import dspy\n",
    "    class VEXSignature(dspy.Signature):\n",
    "        \"\"\"Given vulnerability details from scanners, decide exploitability and produce VEX classification.\n",
    "        Return ONLY strict JSON for: affected, label, reason, risk, remediation.\n",
    "        \"\"\"\n",
    "        cve_id = dspy.InputField(desc=\"CVE or Vulnerability ID\")\n",
    "        package_name = dspy.InputField()\n",
    "        installed_version = dspy.InputField()\n",
    "        fixed_version = dspy.InputField()\n",
    "        severity = dspy.InputField()\n",
    "        title = dspy.InputField()\n",
    "        description = dspy.InputField()\n",
    "        image = dspy.InputField()\n",
    "        scanner = dspy.InputField()\n",
    "        output_json = dspy.OutputField(desc=\"Strict JSON with keys: affected, label, reason, risk, remediation\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print('✓ Prompts module loaded')\n",
    "print(f'Labels: {LABEL_CHOICES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1077885",
   "metadata": {},
   "source": [
    "## Step 5: Scanner Loader Module\n",
    "\n",
    "Loads and normalizes scanner JSON output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Dict, List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "def load_scanner_results(path: str, limit: Optional[int] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Load the combined scanner JSON file (e.g., Trivy + Grype combined).\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the JSON file\n",
    "        limit: If set, only load first N vulnerabilities (for testing)\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Limit vulnerabilities for testing if requested\n",
    "    if limit is not None and \"vulnerabilities\" in data:\n",
    "        data[\"vulnerabilities\"] = data[\"vulnerabilities\"][:limit]\n",
    "        data[\"total_vulnerabilities\"] = len(data[\"vulnerabilities\"])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def _norm(v: Any) -> str:\n",
    "    return \"\" if v is None else str(v)\n",
    "\n",
    "def _extract_vuln_id(rec: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    # Prefer CVE ID if present; else allow GHSA or other IDs\n",
    "    cve = _norm(rec.get(\"cve_id\"))\n",
    "    if cve:\n",
    "        return cve, \"cve\"\n",
    "    # Try common alternate fields\n",
    "    for k in (\"vuln_id\", \"id\", \"ghsa_id\"):\n",
    "        if _norm(rec.get(k)):\n",
    "            return _norm(rec.get(k)), k\n",
    "    # As a last resort, derive from title\n",
    "    title = _norm(rec.get(\"title\"))\n",
    "    if title.startswith(\"CVE-\"):\n",
    "        token = title.split()[0].strip(\",.:;\")\n",
    "        return token, \"derived\"\n",
    "    return \"\", \"unknown\"\n",
    "\n",
    "def build_vuln_frame(data: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"Normalize the vulnerability list into a DataFrame.\"\"\"\n",
    "    image = _norm(data.get(\"image\"))\n",
    "    vulns: List[Dict[str, Any]] = data.get(\"vulnerabilities\", []) or []\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for rec in vulns:\n",
    "        if not isinstance(rec, dict) or not rec:\n",
    "            continue\n",
    "        vuln_id, id_source = _extract_vuln_id(rec)\n",
    "        if not vuln_id:\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"vuln_id\": vuln_id,\n",
    "            \"id_source\": id_source,\n",
    "            \"package_name\": _norm(rec.get(\"package_name\")),\n",
    "            \"installed_version\": _norm(rec.get(\"installed_version\")),\n",
    "            \"fixed_version\": _norm(rec.get(\"fixed_version\")),\n",
    "            \"severity\": _norm(rec.get(\"severity\")),\n",
    "            \"scanner\": _norm(rec.get(\"scanner\")),\n",
    "            \"title\": _norm(rec.get(\"title\")),\n",
    "            \"description\": _norm(rec.get(\"description\")),\n",
    "            \"image\": image or _norm(rec.get(\"image\")),\n",
    "        })\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"vuln_id\", \"id_source\", \"package_name\", \"installed_version\", \"fixed_version\",\n",
    "            \"severity\", \"scanner\", \"title\", \"description\", \"image\"\n",
    "        ])\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "print('✓ Scanner loader module loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e57783d",
   "metadata": {},
   "source": [
    "## Step 6: VEX Reasoner Module\n",
    "\n",
    "Core AI reasoning engine using DSPy or direct Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d853bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "@dataclass\n",
    "class VEXResult:\n",
    "    vuln_id: str\n",
    "    package_name: str\n",
    "    affected: bool\n",
    "    label: str\n",
    "    reason: str\n",
    "    risk: str\n",
    "    remediation: str\n",
    "    raw_model_text: str\n",
    "\n",
    "_JSON_OBJ_RE = re.compile(r\"\\{[\\s\\S]*\\}\")\n",
    "\n",
    "def _safe_json_parse(text: str) -> Optional[Dict[str, Any]]:\n",
    "    # Find first JSON object in the text\n",
    "    m = _JSON_OBJ_RE.search(text)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(m.group(0))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _normalize_label(label: str) -> str:\n",
    "    low = (label or \"\").strip().lower()\n",
    "    for choice in LABEL_CHOICES:\n",
    "        if low == choice:\n",
    "            return choice\n",
    "    # Map common near-misses\n",
    "    aliases = {\n",
    "        \"not_present\": \"code_not_present\",\n",
    "        \"not_reachable\": \"code_not_reachable\",\n",
    "        \"unexploitable\": \"mitigated\",\n",
    "        \"remediated\": \"fixed\",\n",
    "        \"true_positive\": \"vulnerable\",\n",
    "        \"benign\": \"false_positive\",\n",
    "    }\n",
    "    return aliases.get(low, low or \"false_positive\")\n",
    "\n",
    "class _DSPyPredictor:\n",
    "    def __init__(self) -> None:\n",
    "        import dspy\n",
    "        self._predict = dspy.Predict(VEXSignature)\n",
    "\n",
    "    def run_once(self, record: Dict[str, Any]) -> Tuple[str, str]:\n",
    "        out = self._predict(\n",
    "            cve_id=record.get(\"vuln_id\", \"\"),\n",
    "            package_name=record.get(\"package_name\", \"\"),\n",
    "            installed_version=record.get(\"installed_version\", \"\"),\n",
    "            fixed_version=record.get(\"fixed_version\", \"\"),\n",
    "            severity=record.get(\"severity\", \"\"),\n",
    "            title=record.get(\"title\", \"\"),\n",
    "            description=record.get(\"description\", \"\"),\n",
    "            image=record.get(\"image\", \"\"),\n",
    "            scanner=record.get(\"scanner\", \"\"),\n",
    "        )\n",
    "        raw = getattr(out, \"output_json\", None) or str(out)\n",
    "        return str(raw), \"dspy\"\n",
    "\n",
    "class _GeminiFallback:\n",
    "    def __init__(self) -> None:\n",
    "        import google.generativeai as genai\n",
    "        api_key, model = get_gemini_settings()\n",
    "        if not api_key:\n",
    "            raise RuntimeError(\"GEMINI_API_KEY not configured\")\n",
    "        genai.configure(api_key=api_key)\n",
    "        self._model = genai.GenerativeModel(model)\n",
    "\n",
    "    def run_once(self, record: Dict[str, Any]) -> Tuple[str, str]:\n",
    "        user_prompt = f\"\"\"\n",
    "{SYSTEM_INSTRUCTIONS}\n",
    "\n",
    "Vulnerability:\n",
    "- vuln_id: {record.get('vuln_id','')}\n",
    "- package_name: {record.get('package_name','')}\n",
    "- installed_version: {record.get('installed_version','')}\n",
    "- fixed_version: {record.get('fixed_version','')}\n",
    "- severity: {record.get('severity','')}\n",
    "- title: {record.get('title','')}\n",
    "- description: {record.get('description','')}\n",
    "- image: {record.get('image','')}\n",
    "- scanner: {record.get('scanner','')}\n",
    "\n",
    "Return ONLY a strict JSON object.\n",
    "\"\"\".strip()\n",
    "        resp = self._model.generate_content(user_prompt)\n",
    "        text = getattr(resp, \"text\", None) or str(resp)\n",
    "        return str(text), \"gemini\"\n",
    "\n",
    "def _choose_engine() -> Any:\n",
    "    mode = configure_dspy()\n",
    "    if mode == \"dspy\" and VEXSignature is not None:\n",
    "        try:\n",
    "            return _DSPyPredictor()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return _GeminiFallback()\n",
    "\n",
    "def assess_record(engine: Any, rec: Dict[str, Any]) -> VEXResult:\n",
    "    raw_text, used = engine.run_once(rec)\n",
    "    parsed = _safe_json_parse(raw_text) or {}\n",
    "    affected = bool(parsed.get(\"affected\", False))\n",
    "    label = _normalize_label(str(parsed.get(\"label\", \"\")))\n",
    "    reason = str(parsed.get(\"reason\", \"\"))\n",
    "    risk = str(parsed.get(\"risk\", \"\")) or (\"high\" if rec.get(\"severity\", \"\").upper() in {\"CRITICAL\", \"HIGH\"} else \"medium\")\n",
    "    remediation = str(parsed.get(\"remediation\", \"\"))\n",
    "    return VEXResult(\n",
    "        vuln_id=str(rec.get(\"vuln_id\", \"\")),\n",
    "        package_name=str(rec.get(\"package_name\", \"\")),\n",
    "        affected=affected,\n",
    "        label=label,\n",
    "        reason=f\"[{used}] \" + reason if reason else f\"[{used}] no detailed reason\",\n",
    "        risk=risk,\n",
    "        remediation=remediation,\n",
    "        raw_model_text=raw_text,\n",
    "    )\n",
    "\n",
    "def assess_batch(records: Iterable[Dict[str, Any]]) -> List[VEXResult]:\n",
    "    engine = _choose_engine()\n",
    "    results: List[VEXResult] = []\n",
    "    for rec in records:\n",
    "        try:\n",
    "            results.append(assess_record(engine, rec))\n",
    "        except Exception as e:\n",
    "            results.append(VEXResult(\n",
    "                vuln_id=str(rec.get(\"vuln_id\", \"\")),\n",
    "                package_name=str(rec.get(\"package_name\", \"\")),\n",
    "                affected=False,\n",
    "                label=\"error\",\n",
    "                reason=f\"engine_error: {e}\",\n",
    "                risk=\"unknown\",\n",
    "                remediation=\"\",\n",
    "                raw_model_text=\"\",\n",
    "            ))\n",
    "    return results\n",
    "\n",
    "def to_json(results: List[VEXResult]) -> List[Dict[str, Any]]:\n",
    "    return [{\n",
    "        \"vuln_id\": r.vuln_id,\n",
    "        \"package_name\": r.package_name,\n",
    "        \"justification\": {\n",
    "            \"affected\": r.affected,\n",
    "            \"label\": r.label,\n",
    "            \"reason\": r.reason,\n",
    "            \"risk\": r.risk,\n",
    "            \"remediation\": r.remediation,\n",
    "        },\n",
    "        \"raw_model_text\": r.raw_model_text,\n",
    "    } for r in results]\n",
    "\n",
    "def to_markdown(results: List[VEXResult]) -> str:\n",
    "    lines: List[str] = [\"# Vulnerability Assessment Report\", \"\"]\n",
    "    for r in results:\n",
    "        lines.extend([\n",
    "            f\"## {r.vuln_id} — {r.package_name}\",\n",
    "            f\"- Affected: {r.affected}\",\n",
    "            f\"- Label: {r.label}\",\n",
    "            f\"- Risk: {r.risk}\",\n",
    "            \"- Reason:\",\n",
    "            f\"  {r.reason}\",\n",
    "            \"- Remediation:\",\n",
    "            f\"  {r.remediation or 'N/A'}\",\n",
    "            \"\",\n",
    "        ])\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "print('✓ VEX reasoner module loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65047ce",
   "metadata": {},
   "source": [
    "## Step 7: Main Assessment Function\n",
    "\n",
    "Orchestrates the full assessment pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def run_assessment(input_path: str, output_dir: str = '/content/outputs') -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run vulnerability assessment on scanner JSON file.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to combined scanner JSON\n",
    "        output_dir: Directory to save outputs\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with json_path, md_path, and summary_df\n",
    "    \"\"\"\n",
    "    # Load and parse scanner data\n",
    "    print(f'Loading scanner results from: {input_path}')\n",
    "    data = load_scanner_results(input_path, limit=5)\n",
    "    df = build_vuln_frame(data)\n",
    "    \n",
    "    if df.empty:\n",
    "        raise RuntimeError(\"No vulnerabilities found in the provided file.\")\n",
    "    \n",
    "    print(f'Found {len(df)} vulnerability records')\n",
    "    \n",
    "    # De-duplicate to reduce API calls\n",
    "    df_slice = df.sort_values([\"vuln_id\", \"package_name\"]).drop_duplicates([\n",
    "        \"vuln_id\", \"package_name\", \"installed_version\", \"scanner\"\n",
    "    ])\n",
    "    print(f'Processing {len(df_slice)} unique vulnerabilities...')\n",
    "    \n",
    "    # Run assessment\n",
    "    records = df_slice.to_dict(orient=\"records\")\n",
    "    results = assess_batch(records)\n",
    "    \n",
    "    # Convert to output formats\n",
    "    json_out = to_json(results)\n",
    "    md_out = to_markdown(results)\n",
    "    \n",
    "    # Save outputs\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    json_path = os.path.join(output_dir, f\"assessment_{ts}.json\")\n",
    "    md_path = os.path.join(output_dir, f\"assessment_{ts}.md\")\n",
    "    \n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"input\": {\n",
    "                \"image\": data.get(\"image\"),\n",
    "                \"scanners_used\": data.get(\"scanners_used\"),\n",
    "                \"total_vulnerabilities\": data.get(\"total_vulnerabilities\"),\n",
    "                \"source_file\": os.path.abspath(input_path),\n",
    "            },\n",
    "            \"output\": json_out,\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(md_out)\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    df_out = pd.DataFrame(json_out)\n",
    "    df_out[[\"affected\", \"label\", \"reason\", \"risk\", \"remediation\"]] = pd.json_normalize(df_out[\"justification\"])\n",
    "    df_out.drop(columns=[\"justification\"], inplace=True)\n",
    "    \n",
    "    print(f'\\n✓ Assessment complete!')\n",
    "    print(f'  JSON: {json_path}')\n",
    "    print(f'  Markdown: {md_path}')\n",
    "    \n",
    "    return {\n",
    "        \"json_path\": json_path,\n",
    "        \"md_path\": md_path,\n",
    "        \"summary_df\": df_out,\n",
    "    }\n",
    "\n",
    "print('✓ Assessment function loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e74f53",
   "metadata": {},
   "source": [
    "## Step 8: Run Vulnerability Assessment\n",
    "\n",
    "**Note:** This may take 10-30 minutes for ~650 vulnerabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f200670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input file path\n",
    "INPUT_FILE = '/content/LLM-Assisted-Container-Security-Analysis/Scanner/combined_results/hyperledger_fabric-peer_1.1.0_combined.json'\n",
    "\n",
    "# Verify file exists\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    raise FileNotFoundError(f'Scanner file not found: {INPUT_FILE}')\n",
    "\n",
    "print('Starting vulnerability assessment...')\n",
    "print(f'Input: {INPUT_FILE}\\n')\n",
    "\n",
    "# Run assessment\n",
    "result = run_assessment(INPUT_FILE, output_dir='/content/outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167bc6ab",
   "metadata": {},
   "source": [
    "## Step 9: Display Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2cc281",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = result['summary_df']\n",
    "\n",
    "print('\\n=== Vulnerability Assessment Summary ===')\n",
    "print(f'Total assessed: {len(summary_df)}')\n",
    "print(f'Affected: {summary_df[\"affected\"].sum()}')\n",
    "print(f'Not affected: {(~summary_df[\"affected\"]).sum()}')\n",
    "\n",
    "print('\\n=== Label Distribution ===')\n",
    "print(summary_df['label'].value_counts())\n",
    "\n",
    "print('\\n=== Risk Distribution ===')\n",
    "print(summary_df['risk'].value_counts())\n",
    "\n",
    "print('\\n=== First 10 Results ===')\n",
    "display(summary_df[['vuln_id', 'package_name', 'affected', 'label', 'risk']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12b37b",
   "metadata": {},
   "source": [
    "## Step 10: View Detailed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2580dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full results with reasons and remediation\n",
    "print('=== Detailed Results ===')\n",
    "display(summary_df[['vuln_id', 'package_name', 'affected', 'label', 'risk', 'reason', 'remediation']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04caaa1",
   "metadata": {},
   "source": [
    "## Step 11: Filter Specific Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14816dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show only affected vulnerabilities\n",
    "print('=== Affected Vulnerabilities ===')\n",
    "affected = summary_df[summary_df['affected'] == True]\n",
    "display(affected[['vuln_id', 'package_name', 'label', 'risk', 'reason']])\n",
    "\n",
    "# Show high-risk items\n",
    "print('\\n=== High Risk Items ===')\n",
    "high_risk = summary_df[summary_df['risk'] == 'high']\n",
    "display(high_risk[['vuln_id', 'package_name', 'affected', 'label', 'reason']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6edbeae",
   "metadata": {},
   "source": [
    "## Step 12: View JSON Output Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48849d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display JSON structure\n",
    "with open(result['json_path'], 'r', encoding='utf-8') as f:\n",
    "    json_output = json.load(f)\n",
    "\n",
    "print('=== JSON Output Structure ===')\n",
    "print(f\"Keys: {list(json_output.keys())}\")\n",
    "print(f\"\\nInput metadata:\")\n",
    "print(f\"  Image: {json_output['input']['image']}\")\n",
    "print(f\"  Scanners: {json_output['input']['scanners_used']}\")\n",
    "print(f\"  Total vulnerabilities: {json_output['input']['total_vulnerabilities']}\")\n",
    "print(f\"\\nAssessed: {len(json_output['output'])} vulnerabilities\")\n",
    "\n",
    "# Show example result\n",
    "print('\\n=== Example Result ===')\n",
    "print(json.dumps(json_output['output'][0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae8f25",
   "metadata": {},
   "source": [
    "## Step 13: Preview Markdown Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc39c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 50 lines of markdown report\n",
    "with open(result['md_path'], 'r', encoding='utf-8') as f:\n",
    "    md_content = f.read()\n",
    "\n",
    "lines = md_content.split('\\n')\n",
    "preview_lines = min(50, len(lines))\n",
    "print(f'=== Markdown Report Preview (first {preview_lines} lines) ===')\n",
    "print('\\n'.join(lines[:preview_lines]))\n",
    "if len(lines) > 50:\n",
    "    print(f'\\n... ({len(lines) - 50} more lines)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348d907",
   "metadata": {},
   "source": [
    "## Step 14: Generate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive statistics\n",
    "print('=== Comprehensive Statistics ===')\n",
    "print(f'\\nTotal Vulnerabilities: {len(summary_df)}')\n",
    "print(f'Unique CVEs: {summary_df[\"vuln_id\"].nunique()}')\n",
    "print(f'Unique Packages: {summary_df[\"package_name\"].nunique()}')\n",
    "\n",
    "print('\\n--- By Affected Status ---')\n",
    "print(summary_df['affected'].value_counts())\n",
    "\n",
    "print('\\n--- By Label ---')\n",
    "for label, count in summary_df['label'].value_counts().items():\n",
    "    pct = (count / len(summary_df)) * 100\n",
    "    print(f'{label:20s}: {count:4d} ({pct:5.1f}%)')\n",
    "\n",
    "print('\\n--- By Risk Level ---')\n",
    "for risk, count in summary_df['risk'].value_counts().items():\n",
    "    pct = (count / len(summary_df)) * 100\n",
    "    print(f'{risk:20s}: {count:4d} ({pct:5.1f}%)')\n",
    "\n",
    "print('\\n--- Top 10 Most Vulnerable Packages ---')\n",
    "vulnerable_packages = summary_df[summary_df['affected'] == True]['package_name'].value_counts().head(10)\n",
    "for pkg, count in vulnerable_packages.items():\n",
    "    print(f'{pkg:30s}: {count:2d} vulnerabilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084fdb04",
   "metadata": {},
   "source": [
    "## Step 15: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148fa033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download JSON report\n",
    "print('Downloading JSON report...')\n",
    "files.download(result['json_path'])\n",
    "\n",
    "# Download Markdown report\n",
    "print('Downloading Markdown report...')\n",
    "files.download(result['md_path'])\n",
    "\n",
    "print('✓ Downloads initiated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d066bd6",
   "metadata": {},
   "source": [
    "## Notes & Documentation\n",
    "\n",
    "### VEX Labels Used\n",
    "- **vulnerable**: Exploitable as-deployed in this container\n",
    "- **code_not_present**: Package/code not actually present in image\n",
    "- **code_not_reachable**: Present but not reachable/exposed at runtime\n",
    "- **mitigated**: Present but mitigations block exploitation\n",
    "- **fixed**: Fixed version is present\n",
    "- **false_positive**: Scanner likely wrong\n",
    "\n",
    "### Architecture\n",
    "1. **Configuration**: Manages API keys and DSPy setup\n",
    "2. **Scanner Loader**: Parses combined Trivy+Grype JSON\n",
    "3. **Prompts**: Defines system instructions and VEX labels\n",
    "4. **VEX Reasoner**: Core AI engine (DSPy or direct Gemini)\n",
    "5. **Assessment**: Orchestrates full pipeline\n",
    "\n",
    "### Performance\n",
    "- Processing time: ~10-30 minutes for 650 vulnerabilities\n",
    "- Rate limits may apply based on your API key tier\n",
    "- Deduplication reduces API calls significantly\n",
    "\n",
    "### Troubleshooting\n",
    "- **API Key Issues**: Verify key is valid and has quota\n",
    "- **Import Errors**: Re-run Step 1 to reinstall dependencies\n",
    "- **Rate Limits**: Add delays between calls if needed\n",
    "- **DSPy Fallback**: Automatically uses direct Gemini if DSPy fails\n",
    "\n",
    "### Repository\n",
    "GitHub: [satyam-thakur/LLM-Assisted-Container-Security-Analysis](https://github.com/satyam-thakur/LLM-Assisted-Container-Security-Analysis)\n",
    "\n",
    "---\n",
    "*All code is self-contained in this notebook - no external Python files required.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
