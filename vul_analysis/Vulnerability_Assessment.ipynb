{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b8a178",
   "metadata": {},
   "source": [
    "# Vulnerability Assessment (DSPy + Gemini)\n",
    "\n",
    "This notebook loads a combined scanner report (e.g., Trivy + Grype), runs a DSPy/Gemini-based reasoning step to determine exploitability in-context, and saves JSON + Markdown reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92425e01",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Python 3.10+\n",
    "- In `vul_analysis/.env`, set `GEMINI_API_KEY` and optionally `GEMINI_MODEL` (default: `gemini-1.5-flash`).\n",
    "- Install deps from this folder: `pip install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfcaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: quick dependency check (safe to re-run)\n",
    "import importlib, sys, subprocess, os\n",
    "req_pkgs = [\"pandas\", \"dotenv\", \"google.generativeai\", \"dspy\"]\n",
    "missing = [p for p in req_pkgs if importlib.util.find_spec(p) is None]\n",
    "if missing:\n",
    "    print(\"Installing missing packages:\", missing)\n",
    "    _req_path = os.path.join(os.path.dirname(__file__), 'requirements.txt') if '__file__' in globals() else 'requirements.txt'\n",
    "    if os.path.exists(_req_path):\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-r', _req_path])\n",
    "    else:\n",
    "        for p in missing:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', p])\n",
    "else:\n",
    "    print(\"All required packages are available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and paths\n",
    "import os, json\n",
    "from vul_analysis.run_assessment import assess\n",
    "\n",
    "# This notebook resides in vul_analysis/. The scanner file is in ../Scanner/combined_results/\n",
    "INPUT_FILE = r'..\\Scanner\\combined_results\\hyperledger_fabric-peer_1.1.0_combined.json'\n",
    "print('Input file exists:', os.path.exists(INPUT_FILE))\n",
    "INPUT_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbefb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the assessment\n",
    "result = assess(INPUT_FILE)\n",
    "result['summary_df'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d21fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output artifacts\n",
    "print('Saved JSON:', result['json_path'])\n",
    "print('Saved Markdown:', result['md_path'])\n",
    "# Show a compact JSON preview\n",
    "with open(result['json_path'], 'r', encoding='utf-8') as f:\n",
    "    preview = json.load(f)\n",
    "list(preview.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdd9f9",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- If DSPy is unavailable or cannot be configured with Gemini, the pipeline automatically falls back to direct Gemini API calls.\n",
    "- Outputs are written to `vul_analysis/outputs/` with timestamps."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
